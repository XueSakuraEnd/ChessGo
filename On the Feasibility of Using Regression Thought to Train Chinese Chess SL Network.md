# On the Feasibility of Using Regression Thought to Train Chinese Chess SL Network

        This text aims to address the question of whether regression thinking can be used to train the SL network of Chinese Chess. Before delving into that, let's first introduce the SL network of AlphaGo. It trains the probability distribution of move strategies for the current state by inputting a sufficient number of chess game records played by human experts into a CNN network. For the game of Go, which involves placing stones on a board, the probability distribution can be represented as a 19x19 vector, indicating the move probabilities for each grid on the board. This approach is clearly based on a classification mindset.

        However, for Chinese Chess, which is a game involving moving pieces, such a probability distribution is not suitable. We need to use the distribution probability of move strategies, but the number of possible move strategies is not constant, and the representation is also more complicated. Is there another way to solve this problem? First, we need to understand the following key points:

![](https://raw.githubusercontent.com/XueSakuraEnd/Picgo/main/Source/202305071127147.png)

> AlphaGo's SL network training process

        Zobrist Keys: Zobrist Keys are an algorithm that uses 64-bit random hash numbers to distinguish different positions. In Chinese Chess, the specific implementation involves initializing a 7x2x64 array, where the three dimensions represent the piece type, piece color, and piece position. Each element is filled with a 64-bit random number. To generate a Zobrist Key for a position, one simply needs to XOR the previous Zobrist Key with the corresponding random number from the array for the piece being removed, and then XOR it again with the corresponding random number to represent the piece's new position after a move. The effectiveness of distinguishing each position depends on the number of bits in the random numbers and their randomness. In Chinese Chess, using 64-bit random numbers ensures that the probability of encountering different positions with the same Zobrist value is sufficiently low.

$ChessBoard-^{hash⊕kill⊕move_{0}⊕move_{1}}->Zobrist$

        Once we have the Zobrist keys, we can establish a one-to-one mapping between chess positions and Zobrist keys. However, this alone is not sufficient. In order to apply regression thinking, we need to ensure that this mapping relationship exhibits a certain linear correlation. This requires the chess positions to be arranged in a specific order. Since the chess positions are represented by a 10x9 array, I have not found a satisfactory way to regularize the sorting method. Therefore, I have come up with a method called Zobrist serialization.

        Zobrist serialization involves converting the 10x9 array representation of a chess position into a serialized sequence. This sequence is generated by concatenating the elements of the array row by row or column by column, in a specific order. By serializing the chess positions using a consistent pattern, we can establish a linear relationship between the serialized sequence and the corresponding Zobrist keys.

        This Zobrist serialization method provides a structured and orderly representation of chess positions, allowing us to apply regression thinking more effectively in the training of the SL network for Chinese Chess.

        Zobrist Serialization: Due to the nature of XOR operation, Zobrist values to some extent represent the complexity of the current chessboard. By sorting the Zobrist values, we can standardize the chess positions. The sorted chess positions exhibit two key characteristics. First, they have a high degree of linearity with the Zobrist keys. Second, the complexity of the chess positions gradually increases. These two properties offer two advantages when applied to regression CNN networks. 

        Firstly, the feasibility of the linear relationship: The XOR relationship is already solvable in CNN networks, and the high degree of linearity allows the serialized Zobrist keys to be used effectively in training regression CNN networks. 

        Secondly, in terms of prediction: Zobrist serialization simplifies the mapping from the chessboard to the Zobrist keys. In other words, the process of finding the corresponding chess position for a given Zobrist value becomes simpler.

        By leveraging Zobrist serialization, the training of regression CNN networks benefits from the highly linear relationship between serialized Zobrist keys and chess positions. Additionally, the simplified mapping from the chessboard to the Zobrist keys enhances the prediction process.

![](https://raw.githubusercontent.com/XueSakuraEnd/Picgo/main/Source/202305071202145.png)

> The comparison above pertains to the performance of serialized and non-serialized Zobrist keys on over 10,000 chess positions and a subset of 100 moves.

        Indeed, using regression thinking to solve the SL network involves serializing Zobrist keys to establish a linear relationship among numerous mapped chess positions. Essentially, it transforms a multi-class task into a regression task, which offers convenience but also comes with some limitations.

        Firstly, it can be inefficient because the strategy distribution of a single chess position does not have as many variations as the number of possible mappings in the Zobrist key sequence.

        Secondly, there are missing values since the entire sequence is simulated based on a limited number of chess positions from human expert games. Not every possible chess position will be present in the sequence. As a result, the outputs obtained through the SL network can only approximate the nearby positions in terms of their values. This can potentially miss out on better positions, which is a significant flaw when considering the entire game. Therefore, this approach can only be used for the initial estimation of strategy probabilities.

        It's important to recognize these limitations and consider them when applying regression thinking and Zobrist key serialization to the SL network in Chinese Chess.

![](https://raw.githubusercontent.com/XueSakuraEnd/Picgo/main/Source/202305071215001.png)

> The variation in loss values during the training process of the SL network.
